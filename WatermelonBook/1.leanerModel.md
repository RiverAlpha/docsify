# çº¿æ€§æ¨¡å‹

## é›¶åŸºç¡€å¼•å¯¼
åˆ†æç—…äººçš„ç—…æƒ…ä¸€æ ·ï¼Œéœ€è¦å¤šç»´åº¦çš„æ•°æ®ï¼Œæ¯”å¦‚å¹´é¾„ï¼Œè¡€å‹ç­‰ç­‰ï¼Œè€Œä¸”å•ä½è¿˜ä¸ä¸€æ ·ã€‚è¿™é‡Œç®€åŒ–ä¸€ä¸‹æ•°æ®æ¯”å¦‚è¯´ï¼Œæœ‰100ä¸ªæ•°æ®ï¼Œæ¯ä¸ªæ•°æ®ï¼Œè®°å½•äº†ä¸€ä¸ªäººçš„èº«é«˜å’Œä½“é‡ï¼Œç›®æ ‡æ˜¯æˆ‘ä»¬æ±‚ä¸€ä¸ªç³»æ•°$k$ä½¿å¾—ï¼Œ$weight = k*high+b$,æ˜¯ä¸æ˜¯å¾ˆç†Ÿæ‚‰äº†ï¼Œbæ˜¯ä»€ä¹ˆå‘¢ï¼Œbæ˜¯æˆªè·ï¼Œå¯ä»¥ç†è§£ä¸ºè¿™å°±æ˜¯åæ ‡è½´ä¸Šçš„ä¸€æ¡ç›´çº¿ï¼Œè€Œè¿™å°±æ˜¯ç›´çº¿é€šå¼ï¼Œbå½“ç„¶ä¹Ÿå¯èƒ½å°±æ˜¯0ï¼Œä½†æ˜¯åœ¨æ¨¡å‹å»ºç«‹çš„æ—¶å€™å¿…é¡»åŠ ä¸Šã€‚æ‰€ä»¥æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ±‚kå’Œb,å·²è¾¾åˆ°ç»™å‡ºä¸€ä¸ªèº«é«˜å°±å¯ä»¥å¸¦å…¥å…¬å¼æ±‚å‡ºweight.

ç°åœ¨çš„é—®é¢˜æ˜¯æ€ä¹ˆæ±‚kå’Œb. å¯ä»¥ä»è¯¯å·®æœ€å°åŒ–å¼€å§‹åˆ†æï¼Œé¢„æµ‹çš„ä½“é‡æˆ‘ä»¬è¿½å¯»è¯¯å·®æœ€å°ï¼Œè¿™é‡Œå¿…é¡»ç»™å‡ºä¸¤ä¸ªæ•°æ®ï¼Œå®é™…å€¼ï¼ˆ$y_\{å®é™…\}$ï¼‰å’Œé¢„æµ‹å€¼ï¼ˆ$y_\{é¢„æµ‹\}$ï¼‰ï¼Œè¯¯å·®æœ€å°è¡¨ç¤ºè¿™ä¸¤ä¸ªå€¼ç›¸å·®æœ€å°ï¼Œç”¨æ•°å­¦æ€ä¹ˆè¡¨è¾¾å‘¢ï¼Œ
$$
è¯¯å·® = |y_\{å®é™…\} - y_\{é¢„æµ‹\} |
$$
å¦‚æœæƒ³è¦å–æ¶ˆåˆ«çš„è¡¨ç¤ºæ–¹æ³•å»æ‰ç»å¯¹å€¼ä¹Ÿå¯ä»¥ç”¨å¹³æ–¹å’Œè¡¨ç¤º
$$
è¯¯å·® = (y_\{å®é™…\} - y_\{é¢„æµ‹\})^2
$$
å½“ç„¶ï¼Œå¦‚æœè¯¯å·®ç­‰äº0æœ€å¥½ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹åŸºäºç°æœ‰çš„100ä¸ªæ•°æ®ï¼Œå‡è®¾æˆ‘ä»¬å·²ç»æ±‚å‡ºæ¥äº†kå’Œbã€‚æ ¹æ®è¿™ä¸¤ä¸ªå…³é”®çš„å€¼æˆ‘ä»¬å¯ä»¥æ±‚å‡ºæ¯ä¸€ä¸ªäººåŸºäºèº«é«˜å¯¹ä½“é‡çš„é¢„æµ‹å€¼ï¼Œç„¶åï¼Œå°†æ¯ä¸ªçš„é¢„æµ‹å€¼å’Œè‡ªå·±çš„å®é™…å€¼ç›¸å‡å–å¾—çš„ç»å¯¹å€¼å¯ä»¥å¾—åˆ°100ä¸ªè¯¯å·®çš„ç»å¯¹å€¼ï¼Œåˆ™å¯ä»¥è¡¨ç¤ºä¸ºè¿™ä¸€ç™¾ä¸ªç»å¯¹å€¼ç›¸åŠ çš„å€¼è¶Šå°åˆ™è¿™ä¸ªæ¨¡å‹è¶Šå‡†ç¡®ã€‚ä¸ºä»€ä¹ˆè¦å–ç»å¯¹å€¼ä¹Ÿä¸€ç›®äº†ç„¶äº†ï¼Œå¦‚æœæœ‰æ­£æœ‰è´Ÿï¼Œå°±æœ‰å¯èƒ½ç›¸äº’æŠµæ¶ˆäº†ï¼Œç›¸åŠ ä¹‹åå¹¶ä¸èƒ½åæ˜ è¯¯å·®æ€»ä½“å¤§å°ã€‚

![alt text](Gemini_Generated_Image_8x9yyz8x9yyz8x9y.png)

> å…ˆæœ‰é¸¡è¿˜æ˜¯å…ˆæœ‰è›‹

æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ±‚kå’Œd,ä¸Šé¢ç›´æ¥ç»™å‡ºäº†å…·ä½“çš„å€¼æ‰èƒ½æ±‚å‡ºå¯¹åº”çš„é¢„æµ‹å€¼ï¼Œæ‰æœ‰åé¢çš„äº‹ï¼Œä¸å°±æ˜¯çŸ›ç›¾äº†å—ã€‚ä¸Šé¢åªæ˜¯ä¸ºäº†è®©è¯»è€…ç†è§£ä½•ä¸ºè¯¯å·®æœ€å°ã€‚ç°å®æƒ…å†µä¸‹ï¼Œå¹¶ä¸æ˜¯åŸºäºå•ä¸ªèº«é«˜å»é¢„æµ‹ä½“é‡ï¼Œå¯èƒ½è¿˜æœ‰å¹´é¾„ï¼Œä½“è„‚ç‡ï¼Œè…°è‡€è¿™äº›ç›¸å…³ã€‚åŠ å…¥æ¨¡å‹ä¹Ÿå°±æ˜¯å¯¹åº”åŠ ä¸€ä¸ªç³»æ•°è€Œå·²æ¯”å¦‚
$$ä½“é‡ = k_{\text{èº«é«˜}} \cdot èº«é«˜ + k_{\text{ä½“è„‚ç‡}} \cdot ä½“è„‚ç‡ + k_{\text{å¹´é¾„}} \cdot å¹´é¾„ + 1\cdot b$$
è‡³äºè¯¯å·®çš„è®¡ç®—å’Œä¸Šé¢ç›¸åŒã€‚æ‰€ä»¥å°±å˜æˆäº†æ±‚å„ä¸ªæŒ‡æ ‡å¯¹åº”çš„æƒå€¼å’Œæˆªè·çš„é—®é¢˜ã€‚

å°†kè¡¨ç¤ºä¸º$\boldsymbol{k} = (k_{\text{èº«é«˜}}; k_{\text{ä½“è„‚ç‡}}; k_{\text{å¹´é¾„}})$ å‡è®¾æœ‰ä¸€ä¸ªæ•°æ®é¡¹$x$ =(èº«é«˜ï¼š170,ä½“è„‚ç‡ï¼š20%,å¹´é¾„ï¼š60)ï¼Œå°†è¿™ä¸¤ç»„æ•°æ®å¯¹åº”ç›¸ä¹˜å°±æ˜¯é¢„æµ‹å€¼ä½“é‡ã€‚

åœ¨æ•°å­¦ä¸Šå¯å°†è¿™ä¸¤ç§ç±»å‹çš„æ•°æ®è¡¨ç¤ºä¸ºå‘é‡ï¼Œå¯¹åº”ç›¸ä¹˜è¡¨ç¤ºä¸º$$k^\{T\} \cdot x + b$$

## 5.1 åŸºæœ¬å½¢å¼

ç»™å®šç”± $d$ ä¸ªå±æ€§æè¿°çš„ç¤ºä¾‹ $\boldsymbol{x} = (x_1; x_2; \dots; x_d)$ï¼Œå…¶ä¸­ $x_i$ æ˜¯ $\boldsymbol{x}$ åœ¨ç¬¬ $i$ ä¸ªå±æ€§ä¸Šçš„å–å€¼ï¼Œçº¿æ€§æ¨¡å‹ (linear model) è¯•å›¾å­¦å¾—ä¸€ä¸ªé€šè¿‡å±æ€§çš„çº¿æ€§ç»„åˆæ¥è¿›è¡Œé¢„æµ‹çš„å‡½æ•°ï¼Œå³

$$f(\boldsymbol{x}) = w_1x_1 + w_2x_2 + \dots + w_dx_d + b, \tag{3.1}$$

ä¸€èˆ¬ç”¨å‘é‡å½¢å¼å†™æˆ

$$f(\boldsymbol{x}) = \boldsymbol{w}^{\mathrm{T}}\boldsymbol{x} + b, \tag{3.2}$$

å…¶ä¸­ $\boldsymbol{w} = (w_1; w_2; \dots; w_d)$ã€‚$\boldsymbol{w}$ å’Œ $b$ å­¦å¾—ä¹‹åï¼Œæ¨¡å‹å°±å¾—ä»¥ç¡®å®šã€‚

ä¾‹å¦‚è‹¥åœ¨è¥¿ç“œé—®é¢˜ä¸­å­¦å¾— â€œ$f_{\text{å¥½ç“œ}}(\boldsymbol{x}) = 0.2 \cdot x_{\text{è‰²æ³½}} + 0.5 \cdot x_{\text{æ ¹è’‚}} + 0.3 \cdot x_{\text{æ•²å£°}} + 1$â€ï¼Œåˆ™æ„å‘³ç€å¯é€šè¿‡ç»¼åˆè€ƒè™‘è‰²æ³½ã€æ ¹è’‚å’Œæ•²å£°æ¥åˆ¤æ–­ç“œå¥½ä¸å¥½ï¼Œå…¶ä¸­æ ¹è’‚æœ€è¦ç´§ï¼Œè€Œæ•²å£°æ¯”è‰²æ³½æ›´é‡è¦ã€‚

## 5.2 æ±‚è§£ç›®æ ‡

$$
w,å³å¦‚ä½•å¾—åˆ°æ¯ä¸ªå±æ€§ç›¸ä¹˜çš„ç³»æ•°
$$

## 3.2 çº¿æ€§å›å½’

ç»™å®šæ•°æ®é›† $D = (\boldsymbol{x}_1, y_1), (\boldsymbol{x}_2, y_2), \dots, (\boldsymbol{x}_m, y_m)$
ï¼Œå…¶ä¸­$$\boldsymbol{x}_i = (x_\{i1\}; x_\{i2\}; \dots; x_\{id\}) \tag{3.3}$$

æˆ‘ä»¬å…ˆè€ƒè™‘ä¸€ç§æœ€ç®€å•çš„æƒ…å½¢ï¼šè¾“å…¥å±æ€§çš„æ•°ç›®åªæœ‰ä¸€ä¸ªã€‚ä¸ºä¾¿äºè®¨è®ºï¼Œæ­¤æ—¶æˆ‘ä»¬å¿½ç•¥å…³äºå±æ€§çš„ä¸‹æ ‡ï¼Œå³ $D = \{(x_i, y_i)\}_{i=1}^m$ï¼Œå…¶ä¸­ $x_i \in \mathbb{R}$ã€‚

çº¿æ€§å›å½’è¯•å›¾å­¦å¾—
$$f(x_i) = wx_i + b, \text{ ä½¿å¾— } f(x_i) \simeq y_i . \tag{3.3}$$

å¦‚ä½•ç¡®å®š $w$ å’Œ $b$ å‘¢ï¼Ÿæ˜¾ç„¶ï¼Œå…³é”®åœ¨äºå¦‚ä½•è¡¡é‡ $f(x)$ ä¸ $y$ ä¹‹é—´çš„å·®åˆ«ã€‚2.3 èŠ‚ä»‹ç»è¿‡ï¼Œå‡æ–¹è¯¯å·® (2.2) æ˜¯å›å½’ä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„æ€§èƒ½åº¦é‡ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è¯•å›¾è®©å‡æ–¹è¯¯å·®æœ€å°åŒ–ï¼Œå³

$$
(w^*, b^*) = \mathop{\arg\min}_\{(w, b)\} \sum_\{i=1\}^m (f(x_i) - y_i)^2
$$

$$
= \mathop{\arg\min}_\{(w, b)\} \sum_\{i=1\}^m (y_i - wx_i - b)^2 . \tag{3.4}
$$



æ±‚è§£ $w$ å’Œ $b$ ä½¿ $E_\{(w,b)\} = \sum_\{i=1\}^m(y_i - wx_i - b)^2$ æœ€å°åŒ–çš„è¿‡ç¨‹ï¼Œç§°ä¸ºçº¿æ€§å›å½’æ¨¡å‹çš„æœ€å°äºŒä¹˜â€œå‚æ•°ä¼°è®¡â€ (parameter estimation)ã€‚æˆ‘ä»¬å¯å°† $E_\{(w,b)\}$ åˆ†åˆ«å¯¹ $w$ å’Œ $b$ æ±‚å¯¼ï¼Œå¾—åˆ°

$$
\frac{\partial E_\{(w,b)\}}{\partial w} = 2\left(w \sum_\{i=1\}^m x_i^2 - \sum_\{i=1\}^m (y_i - b) x_i\right) \tag{3.5}
$$

$$
\frac{\partial E_\{(w,b)\}}{\partial b} = 2\left(mb - \sum_\{i=1\}^m (y_i - wx_i)\right) \tag{3.6}
$$

ç„¶åä»¤å¼(3.5)å’Œ(3.6)ä¸ºé›¶å¯å¾—åˆ° $w$ å’Œ $b$ æœ€ä¼˜è§£çš„é—­å¼(closed-form)è§£

$$
w = \frac{\sum_\{i=1\}^m y_i(x_i - \bar{x})}{\sum_\{i=1\}^m x_i^2 - \frac{1}{m}\left(\sum_\{i=1\}^m x_i\right)^2} \tag{3.7}
$$

$$
b = \frac{1}{m} \sum_\{i=1\}^m (y_i - wx_i) \tag{3.8}
$$

å…¶ä¸­ $\bar{x} = \frac{1}{m} \sum_\{i=1\}^m x_i$ ä¸º $x$ çš„å‡å€¼ã€‚

### ğŸ’¡ è¡¥å……ï¼šè¯¦ç»†æ¨å¯¼è¿‡ç¨‹ï¼ˆéœ€è¦é«˜æ•°åå¯¼æ•°åŸºç¡€ï¼‰

å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ä¸ºï¼š
$$
E_\{(w,b)\} = \sum_\{i=1\}^m (y_i - wx_i - b)^2
$$

**1. å¯¹ $w$ çš„åå¯¼æ•°æ¨å¯¼ $\frac{\partial E}{\partial w}$**

æ ¹æ®é“¾å¼æ³•åˆ™ï¼Œä»¤ $u_i = y_i - wx_i - b$ï¼Œåˆ™ $\frac{\partial u_i}{\partial w} = -x_i$ã€‚
å¯¹æ±‚å’Œå¼ä¸­çš„æ¯ä¸€é¡¹æ±‚å¯¼ï¼š

$$
\begin{aligned}
\frac{\partial E}{\partial w} &= \frac{\partial}{\partial w} \sum_\{i=1\}^m (y_i - wx_i - b)^2 \\
&= \sum_\{i=1\}^m 2(y_i - wx_i - b) \cdot \frac{\partial}{\partial w}(y_i - wx_i - b) \\
&= \sum_\{i=1\}^m 2(y_i - wx_i - b) \cdot (-x_i) \\
&= 2 \sum_\{i=1\}^m (wx_i^2 + bx_i - y_ix_i) \\
&= 2 \left( w\sum_\{i=1\}^m x_i^2 - \sum_\{i=1\}^m (y_i - b)x_i \right)
\end{aligned} \tag{3.5æ¨å¯¼}
$$

**2. å¯¹ $b$ çš„åå¯¼æ•°æ¨å¯¼ $\frac{\partial E}{\partial b}$**

åŒæ ·åˆ©ç”¨é“¾å¼æ³•åˆ™ï¼Œæ­¤æ—¶ $\frac{\partial u_i}{\partial b} = -1$ã€‚
æ³¨æ„å¸¸æ•°çš„æ±‚å’Œæ€§è´¨ $\sum_\{i=1\}^m b = mb$ï¼š

$$
\begin{aligned}
\frac{\partial E}{\partial b} &= \frac{\partial}{\partial b} \sum_\{i=1\}^m (y_i - wx_i - b)^2 \\
&= \sum_\{i=1\}^m 2(y_i - wx_i - b) \cdot (-1) \\
&= -2 \sum_\{i=1\}^m (y_i - wx_i - b) \\
&= -2 \left( \sum_\{i=1\}^m y_i - \sum_\{i=1\}^m wx_i - \sum_\{i=1\}^m b \right) \\
&= 2 \left( mb - \sum_\{i=1\}^m (y_i - wx_i) \right)
\end{aligned} \tag{3.6æ¨å¯¼}
$$

--------------

### çŸ©é˜µè¡¨è¾¾ï¼ˆéœ€çº¿æ€§ä»£æ•°åŸºç¡€ï¼‰

ç±»ä¼¼çš„ï¼Œå¯åˆ©ç”¨æœ€å°äºŒä¹˜æ³•æ¥å¯¹ $\boldsymbol{w}$ å’Œ $b$ è¿›è¡Œä¼°è®¡ã€‚ä¸ºä¾¿äºè®¨è®ºï¼Œæˆ‘ä»¬æŠŠ $\boldsymbol{w}$ å’Œ $b$ å¸æ”¶å…¥å‘é‡å½¢å¼ $\hat{\boldsymbol{w}} = (\boldsymbol{w}; b)$ï¼Œç›¸åº”çš„ï¼ŒæŠŠæ•°æ®é›† $D$ è¡¨ç¤ºä¸ºä¸€ä¸ª $m \times (d+1)$ å¤§å°çš„çŸ©é˜µ $\mathbf{X}$ï¼Œå…¶ä¸­æ¯è¡Œå¯¹åº”äºä¸€ä¸ªç¤ºä¾‹ï¼Œè¯¥è¡Œå‰ $d$ ä¸ªå…ƒç´ å¯¹åº”äºç¤ºä¾‹çš„ $d$ ä¸ªå±æ€§å€¼ï¼Œæœ€åä¸€ä¸ªå…ƒç´ æ’ç½®ä¸º 1ï¼Œå³

$$
\mathbf{X} = \begin{pmatrix}
x_\{11\} & x_\{12\} & \dots & x_\{1d\} & 1 \\\\
x_\{21\} & x_\{22\} & \dots & x_\{2d\} & 1 \\\\
\vdots & \vdots & \ddots & \vdots & \vdots \\\\
x_\{m1\} & x_\{m2\} & \dots & x_\{md\} & 1
\end{pmatrix} = \begin{pmatrix}
\boldsymbol{x}_1^\mathrm{T} & 1 \\\\
\boldsymbol{x}_2^\mathrm{T} & 1 \\\\
\vdots & \vdots \\\\
\boldsymbol{x}_m^\mathrm{T} & 1
\end{pmatrix}
$$

å†æŠŠæ ‡è®°ä¹Ÿå†™æˆå‘é‡å½¢å¼ $\boldsymbol{y} = (y_1; y_2; \dots; y_m)$ï¼Œåˆ™ç±»ä¼¼å¼(3.4)ï¼Œæœ‰

$$
\hat{\boldsymbol{w}}^* = \mathop{\arg\min}_\{\hat{\boldsymbol{w}}\} (\boldsymbol{y} - \mathbf{X}\hat{\boldsymbol{w}})^\mathrm{T} (\boldsymbol{y} - \mathbf{X}\hat{\boldsymbol{w}}) . \tag{3.9}
$$

ä»¤ $E_\{\hat{\boldsymbol{w}}\} = (\boldsymbol{y} - \mathbf{X}\hat{\boldsymbol{w}})^\mathrm{T} (\boldsymbol{y} - \mathbf{X}\hat{\boldsymbol{w}})$ï¼Œå¯¹ $\hat{\boldsymbol{w}}$ æ±‚å¯¼å¾—åˆ°

$$
\frac{\partial E_\{\hat{\boldsymbol{w}}\}}{\partial \hat{\boldsymbol{w}}} = 2\mathbf{X}^\mathrm{T}(\mathbf{X}\hat{\boldsymbol{w}} - \boldsymbol{y}) . \tag{3.10}
$$

> **ğŸ’¡ è¡¥å……ç»†èŠ‚ï¼šä» (3.9) åˆ° (3.10) çš„çŸ©é˜µæ±‚å¯¼æ¨å¯¼**
>
> 1. **å±•å¼€æŸå¤±å‡½æ•°**ï¼š
> åˆ©ç”¨è½¬ç½®æ€§è´¨ $(A-B)^\mathrm{T} = A^\mathrm{T} - B^\mathrm{T}$ï¼Œå°† $E_{\hat{\boldsymbol{w}}}$ å±•å¼€ï¼š
> $$
> \begin{aligned}
> E_{\hat{\boldsymbol{w}}} &= (\boldsymbol{y}^\mathrm{T} - \hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}) (\boldsymbol{y} - \mathbf{X}\hat{\boldsymbol{w}}) \\
> &= \boldsymbol{y}^\mathrm{T}\boldsymbol{y} - \boldsymbol{y}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}} - \hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}\boldsymbol{y} + \hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}}
> \end{aligned}
> $$
> æ³¨æ„åˆ° $\boldsymbol{y}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}}$ æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œæ ‡é‡çš„è½¬ç½®ç­‰äºå…¶æœ¬èº«ï¼Œå³ $\boldsymbol{y}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}} = (\boldsymbol{y}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}})^\mathrm{T} = \hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}\boldsymbol{y}$ã€‚å› æ­¤ä¸­é—´ä¸¤é¡¹å¯ä»¥åˆå¹¶ï¼š
> $$
> E_{\hat{\boldsymbol{w}}} = \boldsymbol{y}^\mathrm{T}\boldsymbol{y} - 2\hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}\boldsymbol{y} + \hat{\boldsymbol{w}}^\mathrm{T}\mathbf{X}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}}
> $$
>
> 2. **å¯¹å‘é‡ $\hat{\boldsymbol{w}}$ æ±‚å¯¼**ï¼š
> åˆ©ç”¨çŸ©é˜µæ±‚å¯¼å…¬å¼ $\frac{\partial \boldsymbol{x}^\mathrm{T}\boldsymbol{a}}{\partial \boldsymbol{x}} = \boldsymbol{a}$ å’Œ $\frac{\partial \boldsymbol{x}^\mathrm{T}\mathbf{A}\boldsymbol{x}}{\partial \boldsymbol{x}} = 2\mathbf{A}\boldsymbol{x}$ (å½“ $\mathbf{A}$ å¯¹ç§°æ—¶)ï¼š
> * ç¬¬ä¸€é¡¹ $\boldsymbol{y}^\mathrm{T}\boldsymbol{y}$ å¯¹ $\hat{\boldsymbol{w}}$ å¯¼æ•°ä¸º 0ã€‚
> * ç¬¬äºŒé¡¹ $-2\hat{\boldsymbol{w}}^\mathrm{T}(\mathbf{X}^\mathrm{T}\boldsymbol{y})$ å¯¼æ•°ä¸º $-2\mathbf{X}^\mathrm{T}\boldsymbol{y}$ã€‚
> * ç¬¬ä¸‰é¡¹ $\hat{\boldsymbol{w}}^\mathrm{T}(\mathbf{X}^\mathrm{T}\mathbf{X})\hat{\boldsymbol{w}}$ å¯¼æ•°ä¸º $2\mathbf{X}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}}$ã€‚
>
> æœ€ç»ˆå¾—åˆ°ï¼š
> $$
> \frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial \hat{\boldsymbol{w}}} = -2\mathbf{X}^\mathrm{T}\boldsymbol{y} + 2\mathbf{X}^\mathrm{T}\mathbf{X}\hat{\boldsymbol{w}} = 2\mathbf{X}^\mathrm{T}(\mathbf{X}\hat{\boldsymbol{w}} - \boldsymbol{y})
> $$

å³å¾—åˆ°ä¹¦ä¸­å¼(3.10)ï¼š

$$
\frac{\partial E_{\hat{\boldsymbol{w}}}}{\partial \hat{\boldsymbol{w}}} = 2\mathbf{X}^\mathrm{T}(\mathbf{X}\hat{\boldsymbol{w}} - \boldsymbol{y}) . \tag{3.10}
$$

ä»¤ä¸Šå¼ä¸ºé›¶å¯å¾— $\hat{\boldsymbol{w}}$ æœ€ä¼˜è§£çš„é—­å¼è§£ï¼Œä½†ç”±äºæ¶‰åŠçŸ©é˜µé€†çš„è®¡ç®—ï¼Œæ¯”å•å˜é‡æƒ…å½¢è¦å¤æ‚ä¸€äº›ã€‚ä¸‹é¢æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„è®¨è®ºã€‚

å½“ $\mathbf{X}^\mathrm{T}\mathbf{X}$ ä¸ºæ»¡ç§©çŸ©é˜µ(full-rank matrix)æˆ–æ­£å®šçŸ©é˜µ(positive definite matrix)æ—¶ï¼Œä»¤å¼(3.10)ä¸ºé›¶å¯å¾—

$$
\hat{\boldsymbol{w}}^* = (\mathbf{X}^\mathrm{T}\mathbf{X})^{-1}\mathbf{X}^\mathrm{T}\boldsymbol{y} , \tag{3.11}
$$

å…¶ä¸­ $(\mathbf{X}^\mathrm{T}\mathbf{X})^{-1}$ æ˜¯çŸ©é˜µ $(\mathbf{X}^\mathrm{T}\mathbf{X})$ çš„é€†çŸ©é˜µã€‚ä»¤ $\hat{\boldsymbol{x}}_i = (\boldsymbol{x}_i, 1)$ï¼Œåˆ™æœ€ç»ˆå­¦å¾—çš„å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ä¸º

$$
f(\hat{\boldsymbol{x}}_i) = \hat{\boldsymbol{x}}_i^\mathrm{T} (\mathbf{X}^\mathrm{T}\mathbf{X})^{-1} \mathbf{X}^\mathrm{T}\boldsymbol{y} . \tag{3.12}
$$

ç„¶è€Œï¼Œç°å®ä»»åŠ¡ä¸­ $\mathbf{X}^\mathrm{T}\mathbf{X}$ å¾€å¾€ä¸æ˜¯æ»¡ç§©çŸ©é˜µã€‚ä¾‹å¦‚åœ¨è®¸å¤šä»»åŠ¡ä¸­æˆ‘ä»¬ä¼šé‡åˆ°å¤§é‡çš„å˜é‡ï¼Œå…¶æ•°ç›®ç”šè‡³è¶…è¿‡æ ·ä¾‹æ•°ï¼Œå¯¼è‡´ $\mathbf{X}$ çš„åˆ—æ•°å¤šäºè¡Œæ•°ï¼Œ$\mathbf{X}^\mathrm{T}\mathbf{X}$ æ˜¾ç„¶ä¸æ»¡ç§©ã€‚æ­¤æ—¶å¯è§£å‡ºå¤šä¸ª $\hat{\boldsymbol{w}}$ï¼Œå®ƒä»¬éƒ½èƒ½ä½¿å‡æ–¹è¯¯å·®æœ€å°åŒ–ã€‚é€‰æ‹©å“ªä¸€ä¸ªè§£ä½œä¸ºè¾“å‡ºï¼Œå°†ç”±å­¦ä¹ ç®—æ³•çš„å½’çº³åå¥½å†³å®šï¼Œå¸¸è§çš„åšæ³•æ˜¯å¼•å…¥æ­£åˆ™åŒ– (regularization) é¡¹ã€‚

## ä»£ç å®ç°ï¼ˆPythonï¼‰

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ==========================================
# ç¬¬ä¸€æ­¥ï¼šæ¨¡æ‹Ÿæ•°æ® (Data Generation)
# ==========================================
np.random.seed(42) # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯å¤ç°
n_samples = 1000

# 1. éšæœºç”Ÿæˆç‰¹å¾ (Features)
# èº«é«˜: 150cm åˆ° 190cm ä¹‹é—´
height = np.random.normal(170, 10, n_samples) 
# å¹´é¾„: 20å² åˆ° 60å² ä¹‹é—´
age = np.random.randint(20, 60, n_samples)
# ä½“è„‚ç‡: 10% åˆ° 35% ä¹‹é—´ (0.10 - 0.35)
body_fat = np.random.uniform(0.10, 0.35, n_samples)

# 2. å®šä¹‰"ä¸Šå¸è§†è§’"çš„çœŸå®å…³ç³» (Ground Truth)
# å‡è®¾é€»è¾‘ï¼š
# - åŸºç¡€ä½“é‡ (æˆªè·) = -50kg
# - èº«é«˜æ¯å¢åŠ 1cmï¼Œä½“é‡å¢åŠ  0.6kg
# - å¹´é¾„æ¯å¢åŠ 1å²ï¼Œä½“é‡å¢åŠ  0.05kg (ä»£è°¢å˜æ…¢ï¼Œå¾®å¼±å½±å“)
# - ä½“è„‚ç‡æ¯å¢åŠ 100% (å³1.0)ï¼Œä½“é‡å¢åŠ  60kg (æ˜¾è‘—å½±å“)
real_bias = -50
real_weights = [0.6, 0.05, 60] 

# 3. ç”Ÿæˆç›®æ ‡å€¼ (Target: Weight) + æ·»åŠ éšæœºå™ªéŸ³
noise = np.random.normal(0, 2, n_samples) # å™ªéŸ³æ ‡å‡†å·®ä¸º2kg
weight = (real_bias + 
          real_weights[0] * height + 
          real_weights[1] * age + 
          real_weights[2] * body_fat + 
          noise)

# 4. æ•´ç†æˆ DataFrame
data = pd.DataFrame({
    'èº«é«˜(cm)': height,
    'å¹´é¾„(å²)': age,
    'ä½“è„‚ç‡(%)': body_fat,
    'ä½“é‡(kg)': weight
})

print(">>> æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
print(data.head())
print("-" * 30)

# ==========================================
# ç¬¬äºŒæ­¥ï¼šæ¨¡å‹è®­ç»ƒ (Model Training)
# ==========================================

# å‡†å¤‡æ•°æ®
X = data[['èº«é«˜(cm)', 'å¹´é¾„(å²)', 'ä½“è„‚ç‡(%)']]
y = data['ä½“é‡(kg)']

# æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (80% è®­ç»ƒ, 20% æµ‹è¯•)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆå§‹åŒ–å¹¶è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# ==========================================
# ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è¯„ä¼°ä¸è§£é‡Š (Evaluation)
# ==========================================

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¾“å‡ºæ¨¡å‹å­¦åˆ°çš„å‚æ•°
print(">>> æ¨¡å‹å­¦ä¹ ç»“æœ:")
print(f"æˆªè· (Bias): {model.intercept_:.2f} (çœŸå®å€¼: {real_bias})")
print(f"æƒé‡ (Weights):")
print(f"  èº«é«˜: {model.coef_[0]:.2f} (çœŸå®å€¼: {real_weights[0]})")
print(f"  å¹´é¾„: {model.coef_[1]:.2f} (çœŸå®å€¼: {real_weights[1]})")
print(f"  ä½“è„‚ç‡: {model.coef_[2]:.2f} (çœŸå®å€¼: {real_weights[2]})")

# è¯„ä¼°æŒ‡æ ‡
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("-" * 30)
print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.2f}")
print(f"RÂ² åˆ†æ•° (è¶Šæ¥è¿‘1è¶Šå¥½): {r2:.4f}")

# ==========================================
# ç¬¬å››æ­¥ï¼šå¯è§†åŒ– (Visualization)
# ==========================================
plt.figure(figsize=(10, 5))

# ç»˜åˆ¶çœŸå®å€¼ vs é¢„æµ‹å€¼
plt.scatter(y_test, y_pred, alpha=0.5, color='blue')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2) # å®Œç¾é¢„æµ‹çº¿
plt.xlabel('çœŸå®ä½“é‡ (True Weight)')
plt.ylabel('é¢„æµ‹ä½“é‡ (Predicted Weight)')
plt.title('çº¿æ€§å›å½’é¢„æµ‹æ•ˆæœï¼šçœŸå®å€¼ vs é¢„æµ‹å€¼')
plt.grid(True)
plt.show()
```