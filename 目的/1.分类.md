# 分类

> “既然事情已经发生了，那么它发生的概率肯定是最大的”

$$\begin{aligned}
o_{猫} &= x_1 w_{11} + x_2 w_{12} + \dots + b_1 \\\\
o_{狗} &= x_1 w_{21} + x_2 w_{22} + \dots + b_2 \\\\
o_{鸡} &= x_1 w_{31} + x_2 w_{32} + \dots + b_3
\end{aligned}$$

假设现在有3个神经元（其实就是三个线性模型对一个样本的打分）
如果

猫: 2.0

狗: 10.0

鸡: -3.0

如何将量化出的数转化为概率，无论是正负？

> softMax

1. 通常用$f(x) = e^x$函数将一个负数转化为正式，这是一个指数函数，且大的更大，小的更小
2. 可量化总和（不会出现负数抵消情况）
3. 可以归一化（即除以总和可以查看自己的百分比）

所以softmax公式
$$
\boldsymbol{\hat{y_i}} = \frac{e^{o_i}}{\sum^n_ie^{o_i}}
$$

## 如何推导损失函数？

1. 条件概率
在上述的推到中可以得到机器学习分类任务本质就是条件概率，给出一张图，不是猫就是狗或者鸡。也就是给出一张图计算是猫的概率。
> 条件概率
$$
P(y|x) -> P(猫|样本)
$$
也就是给定一个样本且这个样本是猫的概率

2. 样本独立性
各个样本之间不相互依赖，也就是与顺序无关，与样本无关，就像生小孩第一胎是男孩不影响第二胎的性别。
这使得每个联合概率等于各自概率的乘积，比如连续两胎都是男孩的概率等于各自概率乘积即$1/2*1/2$

3. 那什么样的模型算是好模型？

> “既然事情已经发生了，那么它发生的概率肯定是最大的”

算然这句话有点形而上学了，但是这是与数据博弈下的最优解。这让我们有了思路，这就可以转化为将每个样本预测准确得到的概率最大化，如果达到了最大我们的优化任务也就完成了。
那么将所有预测对的样本的概率乘起来并使其最大化。
$$P(\mathbf{Y} | \mathbf{X}) = \prod_{i=1}^n P(y^{(i)} | x^{(i)})$$
需要注意的是这个计算的样本仅仅是预测对的样本$P(y^{(i)} | x^{(i)})$代表x样本本身属于i类，y是属于i类的预测值。

> 溢出隐患 1

需要注意的是如果样本太多，且所有概率都是小于1的，最终的乘积会小的可怜，甚至超过计算机精度。所以对概率乘积取对数，因为对数有性质$log(a*b) = log(a)+log(b)$所以将乘积变成了加。

所以有
$$\log P(\mathbf{Y}|\mathbf{X}) = \sum_{i=1}^n \log P(y^{(i)}|x^{(i)})$$
如果我们使用梯度下降优化，那就需要总损失函数值最小化，但是上述提出要将概率乘积最大化，那加一个负数就可以达到目的，乘积越大，对应的负数就越小。

所以有
$$-\log P(\mathbf{Y}|\mathbf{X}) = \sum_{i=1}^n -\log P(y^{(i)}|x^{(i)})$$

> 那如何计算$P(y^{(i)} | x^{(i)})$

首先根据softmax可能会得到关于三个预测概率比如[猫 0.2, 狗 0.7, 鸟 0.1]，显然我们会将这个样本分类为狗，如果恰恰这个样本本身就是狗，那就是预测对了，这个关于狗概率就会考虑加入最大化式子中。但是如何在代码中自动判别是否预测对了并且如果预测对了就自动加入最大化式子中呢。

想象一下，在最开始将这个样本的真实值转化为[0,1,0]表示这个样本代表狗（[1,0,0]代表猫，[0,0,1]代表鸡），然后根据预测概率列表将最大值设为1，其他都设置为0，然后和真实值比较一下就知道是否预测对了。如果相同代表预测对了然后真实值和预测概率列表[猫 0.2, 狗 0.7, 鸟 0.1]分别相乘然后相加不就行了吗。
> 交叉熵

所以单个$P(y^{(i)} | x^{(i)})$等于
$$l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j$$

用上述的例子就是$\boldsymbol{y} = [0,1,0]$,$\boldsymbol{y} = [0.2,  0.7,  0.1]$
$$
l(\mathbf{y}, \hat{\mathbf{y}}) = -(0 \cdot log(0.2)+1 \cdot log(0.7)+0 \cdot log(0.1)) = -0.7
$$

## 梯度推导

$$\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &= - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\\\
&= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j \\\\
&= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j
\end{aligned}$$

比如第二行中的$\boldsymbol{y} = [0,1,0]$$$\sum^q_{j=1} y_j = 1$$
所以第三行前半部分是常数，

> 梯度(对某个分类进行求导)

$$\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j \\\\= \text{softmax}(\mathbf{o})_j - y_j$$

这个结果很神奇，因为前一项就是预测为j类的概率，如果j代表狗类别，前一项的值就是0.7，然后后面一项就是标签值，这里是1。

所以梯度就是
$$
预测值-真实值
$$

如果预测 0.8，真实是 1，梯度是 $-0.2$（告诉模型：不够大，要把这个 $o_j$ 调大点）。

如果预测 0.8，真实是 0，梯度是 $0.8$（告诉模型：太大了，要把这个 $o_j$ 调小点）。

>交叉熵损失公式 $L = - \sum y_j \log \hat{y}_j$ 里，因为 $y_\{\text{错误}} = 0$，也就是那些错误类别的项直接被乘 0 消除掉了。看起来损失函数压根“没看”那些错误类别。那为什么梯度还要去更新那些错误类别的权重呢？

### 零和游戏

残酷的是，三个类别加起来的概率是一，如果想要提高某一个类别的准确率必须拉低错误分类的概率，也就是零和博弈。不是共赢。

如果预测对了梯度是负数，需要增加。如果预测错了，梯度是正数，需要减小

> 溢出隐患 2

设想如果给一个样本的一个分类大的分太大，再应用到$e^x$身上。还是有可能溢出。所以，基于$e^x$的性质，用每个分数减去最大值作为softmax原始输入
$$
\overline{o} = max_ko_k
$$
$$
\hat{y}_j = \frac{\exp o_j}{\sum_k \exp o_k} = \frac{\exp(o_j - \bar{o}) \exp \bar{o}}{\sum_k \exp(o_k - \bar{o}) \exp \bar{o}} = \frac{\exp(o_j - \bar{o})}{\sum_k \exp(o_k - \bar{o})}
$$
取对数
$$
\log \hat{y}_j = \log \frac{\exp(o_j - \bar{o})}{\sum_k \exp(o_k - \bar{o})} = o_j - \bar{o} - \log \sum_k \exp(o_k - \bar{o})
$$

- 梯度并没有变化